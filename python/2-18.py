### **Day 18 â€” å¤šå·¥å…·è°ƒç”¨é“¾**
# ç»ƒä¹ ï¼šè®©æ¨¡å‹å…ˆæœç´¢ï¼Œå†æ€»ç»“



# ç›®æ ‡ï¼š
#     ä½¿ç”¨toolså¤šå·¥å…·è°ƒç”¨é“¾

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain.agents import create_agent



# 1. åŠ è½½ç¯å¢ƒ
load_dotenv()


# 2. å®šä¹‰å·¥å…·
@tool
def get_weather(city: str):
    """æŸ¥è¯¢å¤©æ°”"""
    return f"{city}çš„å¤©æ°”æ˜¯ï¼šæ™´å¤©ï¼Œ25åº¦"

@tool
def multiply(a: int, b: int):
    """è®¡ç®—ä¹˜æ³•"""
    return a * b



tools = [get_weather, multiply]

# 3. å‡†å¤‡æ¨¡å‹ (Qwen/GPT)
llm = ChatOpenAI(
    model="qwen-turbo", 
    api_key=os.getenv("ALIYUN_API_KEY"),
    base_url=os.getenv("ALIYUN_MODEL_BASEURL"),
    temperature=0
)

# 4. åˆ›å»º Agent (æ–°ç‰ˆå†™æ³•)
# æ³¨æ„ï¼šv1.0 é‡Œçš„ create_agent ç›´æ¥æ¥å— model å’Œ tools
# å®ƒå†…éƒ¨å·²ç»æŠŠ "Prompt" å’Œ "Executor" çš„é€»è¾‘å…¨åŒ…äº†
print("ğŸ¤– æ­£åœ¨æ„å»º v1.0 æ–°ç‰ˆ Agent...")

agent = create_agent(
    model=llm,
    tools=tools,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨å·¥å…·è§£å†³é—®é¢˜ã€‚"
)


# 5. è¿è¡Œ (ç›´æ¥ invoke agentï¼Œä¸éœ€è¦ executor)
print("ğŸš€ Agent å¯åŠ¨ä¸­...")
result = agent.invoke({
    "messages": [
        ("user", "æŸ¥ä¸€ä¸‹ä¸Šæµ·å’ŒåŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åç®—å‡º 299 ä¹˜ä»¥ 5 æ˜¯å¤šå°‘ï¼Ÿè¿˜è¦é…¸æ¥š5é™¤ä»¥1ç­‰äºå‡ ")
    ]
})


# 6. æ‰“å°ç»“æœ
# v1.0 çš„è¿”å›ç»“æœé€šå¸¸æ˜¯ä¸€ä¸ªåŒ…å« 'messages' çš„å­—å…¸ï¼Œæœ€åä¸€æ¡æ˜¯ AI çš„å›ç­”
print("-" * 30)
print(result["messages"][-1].content)








