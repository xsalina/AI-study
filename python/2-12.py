# ### **Day 12 â€” é•¿ä¸Šä¸‹æ–‡æ§åˆ¶æŠ€å·§**
# å†…å®¹ï¼šæ‘˜è¦ã€å‹ç¼©ã€ç»“æ„æç‚¼
# ç»ƒä¹ ï¼šè®©æ¨¡å‹å¯¹é•¿æ–‡æ¡£æç‚¼å…³é”®ç‚¹

# ç—›ç‚¹ï¼š
#     AI çš„â€œè„‘å®¹é‡â€æ˜¯æœ‰é™çš„

# ç†è§£ï¼š
#     A. æ‘˜è¦ (Summarization) -> â€œæŠŠä¹¦è¯»è–„â€
#             å·¥ç¨‹è§†è§’ï¼šå¦‚æœæ–‡ç« æœ‰ 10 ä¸‡å­—ï¼Œæ¨¡å‹ä¸€æ¬¡åªèƒ½åƒ 1 ä¸‡å­—ã€‚ä½ æ€ä¹ˆåšæ€»ç»“ï¼Ÿ
#             ç­–ç•¥ï¼šä½ å¾—å…ˆæŠŠ 10 ä¸‡å­—åˆ‡æˆ 10 æ®µï¼Œæ¯æ®µè®© AI è¯»ä¸€éå†™ä¸ªâ€œå°æ€»ç»“â€ï¼ˆè¿™æ˜¯ Map è¿‡ç¨‹ï¼‰ï¼Œæœ€åæŠŠ 10 ä¸ªâ€œå°æ€»ç»“â€æ‹¼èµ·æ¥ï¼Œå†å†™ä¸ªâ€œæ€»æ€»ç»“â€ï¼ˆè¿™æ˜¯ Reduce è¿‡ç¨‹ï¼‰ã€‚
#             åº”ç”¨åœºæ™¯ï¼šä½ çš„è‚¡ç¥¨åŠ©æ‰‹è¦åˆ†æâ€œæŸå…¬å¸è¿‡å» 5 å¹´çš„æ‰€æœ‰æ–°é—»â€ï¼Œç”Ÿæˆä¸€ä»½ç ”æŠ¥ã€‚
#     B. å‹ç¼© (Compression) -> â€œå»ä¼ªå­˜çœŸâ€
#             å·¥ç¨‹è§†è§’ï¼šåœ¨ä¸ä¸¢å¤±æ ¸å¿ƒä¿¡æ¯çš„å‰æä¸‹ï¼Œæå¤§åœ°å‡å°‘ Token æ¶ˆè€—ã€‚
#             ä¾‹å­ï¼šä¼šè®®çºªè¦é‡Œæœ‰å¾ˆå¤šåºŸè¯ï¼šâ€œé‚£ä¸ª...é‚£ä¸ª...æˆ‘è§‰å¾—å§...â€ã€‚
#             ç›®æ ‡ï¼šæŠŠ 5000 å­—çš„åºŸè¯å‹ç¼©æˆ 500 å­—çš„å¹²è´§ï¼Œåªä¿ç•™ AI ä¸‹ä¸€æ­¥æ¨ç†éœ€è¦çš„äº‹å®ï¼Œæ‰”æ‰ä¿®é¥°è¯­ã€‚
#     C. ç»“æ„æç‚¼ (Structure Extraction) -> â€œæŠŠæ–‡æœ¬å˜æ•°æ®åº“â€
#             å·¥ç¨‹è§†è§’ï¼šè¿™æ˜¯æœ€å€¼é’±çš„éƒ¨åˆ†ã€‚æŠŠéç»“æ„åŒ–çš„â€œä¸€å¨å­—â€ï¼Œå˜æˆç»“æ„åŒ–çš„ JSONã€‚
#             åœºæ™¯ï¼š
#             è¾“å…¥ï¼šä¸€ç¯‡ 2 ä¸‡å­—çš„â€œç‰¹æ–¯æ‹‰æŠ•èµ„è€…æ—¥â€æ¼”è®²ç¨¿ã€‚
#             è¾“å‡ºï¼šä¸æ˜¯ä¸€æ®µè¯ï¼Œè€Œæ˜¯ä¸€ä¸ª JSON åˆ—è¡¨ï¼š
#                 [
#                     {"product": "Cybertruck", "launch_date": "2023-Q4", "price_change": "N/A"},
#                     {"product": "Model 2", "launch_date": "2025", "status": "Planning"}
#                 ]
#             è¿™å°±å«â€œç»“æ„æç‚¼â€ã€‚è¿™èƒ½è®©ä½ æŠŠé•¿æ–‡æ¡£å˜æˆå¯ä»¥å­˜è¿›æ•°æ®åº“çš„æ•°æ®ã€‚

# æ€»ç»“:
#     å½“é¢å¯¹æµ·é‡æ–‡æœ¬æ—¶ï¼Œå¦‚ä½•è®¾è®¡ä¸€ä¸ªâ€œæµæ°´çº¿â€ï¼Œè®© AI åˆ†æ‰¹æ¬¡ã€æœ‰ç­–ç•¥åœ°æŠŠé‡Œé¢çš„â€œé‡‘å­â€ï¼ˆå…³é”®ä¿¡æ¯ã€ç»“æ„åŒ–æ•°æ®ï¼‰æ·˜å‡ºæ¥ï¼Œè€Œä¸æ˜¯ä¸€è‚¡è„‘å¡è¿›å»ç­‰ç€æŠ¥é”™ã€‚


import os
from pathlib import Path
from dotenv import load_dotenv
# 1. å¼•å…¥ LangChain çš„ OpenAI è¿æ¥å™¨
from langchain_openai import ChatOpenAI
# 1. å¯¼å…¥åˆ‡åˆ†å·¥å…·
# RecursiveCharacterTextSplitter æ˜¯æœ€å¸¸ç”¨çš„â€œæ™ºèƒ½åˆ‡åˆ€â€
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser # ç”¨æ¥æŠŠç»“æœè½¬æˆå­—ç¬¦ä¸²

# --- A. åŠ è½½ç¯å¢ƒå˜é‡ (å’Œä½ ä¹‹å‰çš„ä½œä¸šä¸€æ ·) ---
current_dir = Path(__file__).parent
env_path = current_dir / ".env"
load_dotenv(dotenv_path=env_path)

llm = ChatOpenAI(
    api_key=os.getenv('ALIYUN_API_KEY'),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-turbo",
    temperature=0.7,
)

# if __name__ == "__main__":
    # print("ğŸ¤– æ­£åœ¨å‘¼å«é€šä¹‰åƒé—®...")
    # try:
        # response = llm.invoke('ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä¸€ä¸‹ LangChain æ˜¯ä»€ä¹ˆï¼Ÿ')
        # LangChain æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ï¼Œå¸®åŠ©å¼€å‘è€…æ›´é«˜æ•ˆåœ°é›†æˆå’Œç®¡ç†è¯­è¨€æ¨¡å‹çš„è¾“å…¥è¾“å‡ºæµç¨‹ã€‚
        # print(response.content)
    # except Exception as e:
    #     print("âŒ æŠ¥é”™äº†ï¼š", e)



long_text = """
ã€ç‰¹æ–¯æ‹‰é‡ç£…æ–°é—»ã€‘
ç‰¹æ–¯æ‹‰ä»Šæ—¥å®£å¸ƒï¼Œå…¶æ–°æ¬¾ Model 2 è½¦å‹å°†äº 2025 å¹´æ­£å¼é‡äº§ã€‚
è¿™æ¬¾è½¦å‹é¢„è®¡å”®ä»·ä¸º 2.5 ä¸‡ç¾å…ƒï¼Œæ—¨åœ¨æŠ¢å å…¥é—¨çº§ç”µåŠ¨è½¦å¸‚åœºã€‚
é©¬æ–¯å…‹åœ¨ç”µè¯ä¼šè®®ä¸­è¡¨ç¤ºï¼šâ€œè¿™æ˜¯ç‰¹æ–¯æ‹‰å†å²ä¸Šæœ€é‡è¦çš„æ—¶åˆ»ã€‚â€
""" * 5

print(f"ğŸ“„ åŸå§‹æ–‡æœ¬: {long_text}")

# 2. æç«¯åˆ‡åˆ†æµ‹è¯•
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 200,    # æ¯å—åªè£… 10 ä¸ªå­—
    chunk_overlap = 50,  # å¿…é¡»é‡å  5 ä¸ªå­—
    separators=[""]     # å¼ºåˆ¶æŒ‰å­—ç¬¦åˆ‡ï¼Œä¸è€ƒè™‘å¥å­å®Œæ•´æ€§ï¼ˆä¸ºäº†çœ‹æ•ˆæœï¼‰
)

docs = text_splitter.create_documents([long_text])

print("\n--- éªŒè¯ç»“æœ ---")
print(f"ğŸ”ª ç¬¬ 1 å—: {docs[0].page_content}") 

# --- 3. å®šä¹‰ Map æŒ‡ä»¤ (å‹ç¼©æŒ‡ä»¤) ---
# è¿™ä¸ªæŒ‡ä»¤ä¼šè¢«å‘é€ç»™æ¯ä¸€ä¸ªç¢ç‰‡
map_template = """
è¯·é˜…è¯»ä¸‹é¢çš„æ–‡æœ¬ç‰‡æ®µã€‚
ä»»åŠ¡ï¼šæå–æ ¸å¿ƒä¿¡æ¯ï¼ˆäº§å“ã€ä»·æ ¼ã€æ—¶é—´ï¼‰ï¼Œå»é™¤é‡å¤å’ŒåºŸè¯ã€‚
å¦‚æœè¿™æ®µè¯é‡Œæ²¡æœ‰å…³é”®ä¿¡æ¯ï¼Œè¯·ç›´æ¥å›ç­”â€œæ— â€ã€‚

æ–‡æœ¬ç‰‡æ®µï¼š
"{text}"

ç²¾ç®€åçš„ä¿¡æ¯ï¼š
"""

map_prompt = PromptTemplate.from_template(map_template)
# --- 4. æ‰‹åŠ¨æ‰§è¡Œ Map è¿‡ç¨‹ (ä¸ºäº†çœ‹æ¸…è¿‡ç¨‹) ---
# å»ºç«‹ä¸€æ¡å°æµæ°´çº¿ï¼š Prompt -> LLM -> å­—ç¬¦ä¸²è§£æ

map_chain = map_prompt | llm | StrOutputParser()

input_data = [{'text': doc.page_content} for doc in docs]

map_results = map_chain.batch(input_data)

# --- 5. å±•ç¤ºç»“æœ ---
print("\nğŸ‘€ å¯¹æ¯”ä¸€ä¸‹æ•ˆæœï¼š")

for i,res in enumerate(map_results):
    print(f"--- ç¬¬ {i+1} å— ---")
    print(f"ğŸ“¥ [è¾“å…¥] é•¿åº¦ {len(docs[i].page_content)} å­—")
    print(f"ğŸ“¤ [è¾“å‡º] ç»“æœ: {res}")
    print("----------------")


print("\nğŸš€ å¼€å§‹ Reduce é˜¶æ®µ (åˆå¹¶å»é‡ + è½¬ JSON)...")

# 1. ç‰©ç†åˆå¹¶ï¼šæŠŠé‚£å‡ ä¸ªé‡å¤çš„ç­”æ¡ˆæ‹¼æˆä¸€ä¸ªé•¿å­—ç¬¦ä¸²
# æ•ˆæœï¼š "äº§å“: Model 2...\näº§å“: Model 2...\n..."
combined_text = "\n".join(map_results)
# 2. å®šä¹‰ Reduce æŒ‡ä»¤ (è¿™ä¸€æ­¥æœ€å…³é”®)
reduce_template = """
è¿™é‡Œæœ‰ä¸€ç»„ä»é•¿æ–‡æ¡£ä¸­æå–çš„ä¿¡æ¯ç‰‡æ®µï¼ˆå…¶ä¸­åŒ…å«å¾ˆå¤šé‡å¤å†…å®¹ï¼‰ï¼š
---
{text}
---

ä½ çš„ä»»åŠ¡ï¼š
1. ã€å»é‡ã€‘ï¼šç»¼åˆæ‰€æœ‰ä¿¡æ¯ï¼Œå»é™¤é‡å¤çš„å†…å®¹ã€‚
2. ã€æ ¼å¼åŒ–ã€‘ï¼šå°†æœ€ç»ˆç»“æœæ•´ç†ä¸ºæ ‡å‡†çš„ JSON æ ¼å¼ã€‚
3. ã€å­—æ®µã€‘ï¼š
   - product_name (äº§å“åç§°)
   - price (ä»·æ ¼)
   - launch_date (å‘å¸ƒæ—¶é—´)
   - stock_status (è‚¡ä»·æƒ…å†µï¼Œå¦‚æœæ²¡æœ‰åˆ™å¡« null)

âš ï¸ æ³¨æ„ï¼šåªè¾“å‡ºçº¯ JSON å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚

æœ€ç»ˆç»“æœï¼š
"""

reduce_prompt = PromptTemplate.from_template(reduce_template)
# 3. ç»„è£… Reduce æµæ°´çº¿
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æŠŠ temperature è®¾ä¸º 0ï¼Œè®© AI ä¸¥è°¨ä¸€ç‚¹ï¼Œåˆ«å†™é”™ JSON æ ¼å¼
reduce_llm = ChatOpenAI(
    api_key=os.getenv("ALIYUN_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    model="qwen-turbo",
    temperature=0  # ğŸ‘ˆ ä¸¥è°¨æ¨¡å¼
)

reduce_chain = reduce_prompt | reduce_llm | StrOutputParser()

# 4. æ‰§è¡Œï¼
final_json = reduce_chain.invoke({"text": combined_text})

print("\nğŸ“Š æœ€ç»ˆ JSON ç»“æœï¼š")
print(final_json)



# ä½ ä»Šå¤©å­¦ä¼šäº† LLM å¼€å‘ä¸­æœ€é‡è¦çš„ â€œé•¿æ–‡æ¡£å¤„ç†æ¨¡å¼â€ (Map-Reduce)ï¼š

# TextSplitterï¼šç‰©ç†åˆ‡åˆ†ï¼Œä¸èŠ±é’±ã€‚

# LCEL æµæ°´çº¿ (|)ï¼šæŠŠ Promptã€æ¨¡å‹ã€è§£æå™¨ä¸²èµ·æ¥ã€‚

# Map-Reduce æ€æƒ³ï¼šåˆ†è€Œæ²»ä¹‹ï¼Œæœ€åæ±‡æ€»ã€‚