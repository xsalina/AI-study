
# Day 27: ä¸“ä¸šçš„ Markdown æ¸²æŸ“ä¸äº¤äº’
# ä»»åŠ¡: è®©èŠå¤©æ°”æ³¡æ”¯æŒä»£ç é«˜äº®ã€è¡¨æ ¼ã€å…¬å¼ã€‚
# æŠ€æœ¯: react-markdown, syntax-highlighterã€‚
# æˆæœ: ä¸€ä¸ªç•Œé¢ç²¾ç¾ã€äº¤äº’ä¸æ»‘çš„ AI èŠå¤©çª—å£ã€‚





import os
import shutil
import tempfile
import time # <--- æ–°å¢è¿™è¡Œ
from fastapi import FastAPI,UploadFile,File,Form,HTTPException
from pydantic import BaseModel
from dotenv import load_dotenv



from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.chat_models import ChatTongyi
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_classic.chains import create_retrieval_chain
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate




load_dotenv()


# åˆå§‹åŒ–app
app = FastAPI(
    title = 'Day 24: AI åç«¯æ¶æ„'
)


app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=['*'],
    allow_headers=['*']
)

# --- 2. æ ¸å¿ƒæ¶æ„ï¼šå…¨å±€ä»“åº“ (Global Storage) ---
RAG_CHAINS = { }  # ç”¨äºå­˜å‚¨æ¯ä¸ªç”¨æˆ·çš„ RAG Chain å®ä¾‹   

class ChatRequest(BaseModel):
    session_id: str = "default_user"
    query: str



# --- 4. æ ¸å¿ƒé€»è¾‘å‡½æ•° (åªè´Ÿè´£é€ å¤§è„‘ï¼Œä¸è´Ÿè´£ç½‘ç»œ) ---
def build_rag_chain_from_file(local_pdf_path):
    print(f"âš™ï¸ å¼€å§‹å¤„ç†æ–‡ä»¶: {local_pdf_path} ...")
    # A. åŠ è½½
    pdf = PyPDFLoader(local_pdf_path)
    docs = pdf.load()
    print("âš™ï¸ æ­£åœ¨è°ƒç”¨ tempfile11...")
    # åˆ‡åˆ†
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    print(f"ğŸ“„ æ–‡æ¡£å·²åˆ‡åˆ†ä¸º {len(splits)} æ®µã€‚")

    print("âš™ï¸ æ­£åœ¨è°ƒç”¨ tempfile22...")
    # å»ºåº“
    embeddings = DashScopeEmbeddings(model="text-embedding-v1", dashscope_api_key=os.getenv("ALIYUN_API_KEY"))
    vectorstore = Chroma.from_documents(documents=splits,embedding=embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k":5})
    print("âš™ï¸ æ­£åœ¨è°ƒç”¨ tempfile33...")

    # D. æ„å»ºé“¾ (ç®€å•çš„é—®ç­”é“¾ï¼Œæš‚ä¸åŠ å¤æ‚è®°å¿†ï¼Œä¿è¯å…ˆè·‘é€š)
    # æ‰¾åˆ° system_promptï¼Œæ›¿æ¢æˆä¸‹é¢è¿™æ®µï¼š
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚
    è¯·ä¼˜å…ˆåŸºäºä»¥ä¸‹ Context å›ç­”é—®é¢˜ã€‚
    
    ã€é‡è¦è§„åˆ™ã€‘
    1. å¦‚æœ Context é‡Œæœ‰ç­”æ¡ˆï¼Œè¯·ä¾æ® Context å›ç­”ã€‚
    2. å¦‚æœ Context é‡Œæ²¡æœ‰ç­”æ¡ˆï¼ˆæ¯”å¦‚ç”¨æˆ·é—®é€šç”¨çŸ¥è¯†ã€ä»£ç é—®é¢˜ï¼‰ï¼Œè¯·**ä½¿ç”¨ä½ è‡ªå·±çš„çŸ¥è¯†**å›ç­”ï¼Œä¸è¦è¯´ä¸çŸ¥é“ã€‚
    3. å¦‚æœéœ€è¦å†™ä»£ç ï¼Œè¯·ä½¿ç”¨ Markdown ä»£ç å—æ ¼å¼ã€‚
    4. å¦‚æœæ¶‰åŠå¯¹æ¯”ï¼Œè¯·å°½é‡ä½¿ç”¨ Markdown è¡¨æ ¼ã€‚
    
    <context>
    {context}
    </context>
    """
    prompt = ChatPromptTemplate.from_messages([("system",system_prompt),("human","{input}"),])
    print("âš™ï¸ æ­£åœ¨è°ƒç”¨ tempfile44...")

    llm = ChatTongyi(model="qwen-turbo",dashscope_api_key=os.getenv("ALIYUN_API_KEY"))
    print("âš™ï¸ æ­£åœ¨è°ƒç”¨ tempfile55...")
    question_answer_chain = create_stuff_documents_chain(llm,prompt)
    rag_chain = create_retrieval_chain(retriever,question_answer_chain)

    print("âœ… RAG é“¾æ„å»ºå®Œæˆï¼")
    return rag_chain







@app.post("/upload")

async def upload_pdf(session_id: str = Form('default_user'), file: UploadFile = File(...)):
    # 1. ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
    # (FastAPI æ¥æ”¶çš„æ˜¯å†…å­˜æµï¼ŒPyPDFLoader éœ€è¦ç‰©ç†è·¯å¾„ï¼Œæ‰€ä»¥è¦å­˜ä¸€ä¸‹)
    with tempfile.NamedTemporaryFile(delete=False,suffix='.pdf') as tmp_file:
        shutil.copyfileobj(file.file,tmp_file)
        tmp_path = tmp_file.name
    try:
        print("âš™ï¸ æ­£åœ¨è°ƒç”¨ tempfile...")
        
        # 2. è°ƒç”¨ä¸Šé¢çš„é€»è¾‘å‡½æ•°ï¼Œç”Ÿæˆ AI å¤§è„‘
        rag_chain = build_rag_chain_from_file(tmp_path)
        # 3. æŠŠé€ å¥½çš„å¤§è„‘å­˜è¿›å…¨å±€å­—å…¸
        RAG_CHAINS[session_id] = rag_chain
        return {
            "message": "PDF å¤„ç†æˆåŠŸï¼å¤§è„‘å·²æ¿€æ´»ï¼Œå¯ä»¥å¼€å§‹æé—®äº†ã€‚",
            "filename":file.filename,
            "session_id":session_id
        }
    
    except Exception as e :
        print(f"å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        # 4. æ¸…ç†åƒåœ¾ (åˆ é™¤é‚£ä¸ªä¸´æ—¶å­˜çš„ PDF)
        if os.path.exists(tmp_path):
            os.remove(tmp_path)



@app.post("/chat")
def chat(request:ChatRequest):
    # å…ˆæŸ¥è¿™ä¸ªæˆ·å£æœ‰æ²¡æœ‰ä¸Šä¼ è¿‡
    if request.session_id not in RAG_CHAINS:
        raise HTTPException(status_code = 400, detail="è¯·å…ˆä¸Šä¼ æ–‡ä»¶")
    
    # å–å‡ºå¤§è„‘
    brain = RAG_CHAINS[request.session_id]

    print(f"ğŸ’¬ ç”¨æˆ· {request.session_id} é—®: {request.query}")

    # 3. æ€è€ƒ (Invoke)

    response = brain.invoke({"input":request.query})

    # 3. å‡è£…å›ç­”
    return {
        "answer": response["answer"],
        # è¿™é‡Œæˆ‘ä»¬ä¹ŸæŠŠå‚è€ƒæ¥æºè¿”å›å»ï¼Œæ˜¾å¾—ä¸“ä¸š
        "sources":[doc.page_content[:50] + "..." for doc in response["context"]]
    }


# --- æ–°å¢ï¼šæµå¼æé—®æ¥å£ (Day 25 æ ¸å¿ƒ) ---
@app.post('/chat/stream')
async def chat_stream(request:ChatRequest):
    # 1. æ£€æŸ¥ Session
    if request.session_id not in RAG_CHAINS:
        raise HTTPException(status_code=400, detail="è¯·å…ˆä¸Šä¼  PDF æ–‡ä»¶ï¼")
    
    chain = RAG_CHAINS[request.session_id]
    
    print(f"ğŸŒŠ ç”¨æˆ· {request.session_id} æ­£åœ¨è¿›è¡Œæµå¼æé—®: {request.query}")
    # 2. å®šä¹‰ç”Ÿæˆå™¨å‡½æ•°
    def generate_response():
        # chain.stream() ä¼šè‡ªåŠ¨ä¸€ä¸ªå­—ä¸€ä¸ªå­—åœ°åæ•°æ®
        for chunk in chain.stream({"input":request.query}):
            # LangChain çš„ stream è¿”å›çš„å¾ˆç¢ï¼Œæˆ‘ä»¬éœ€è¦æå–å‡º answer éƒ¨åˆ†
            if "answer" in chunk:
                content = chunk["answer"]
                if content:
                    # ğŸŒ ã€æ–°å¢ã€‘äººå·¥å»¶è¿Ÿï¼šæ¯è¾“å‡ºä¸€ä¸ªå—ï¼Œæš‚åœ 0.05 ç§’
                    # ä½ å¯ä»¥è°ƒæ•´è¿™ä¸ªæ•°å­—ï¼š0.02 å¾ˆæµç•…ï¼Œ0.1 å°±å¾ˆæœ‰â€œè€ç”µå½±æ‰“å­—æœºâ€çš„æ„Ÿè§‰
                    yield content
    # 3. æŠŠç”Ÿæˆå™¨äº¤ç»™ FastAPI çš„ä¼ é€å¸¦
    return StreamingResponse(
        generate_response(),
        media_type="text/event-stream" # å‘Šè¯‰æµè§ˆå™¨ï¼šæˆ‘æ˜¯æµï¼Œåˆ«æ€¥ç€æ–­å¼€
    )



