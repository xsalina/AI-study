# Day 21: ä½ çš„ AI ä¼šé˜…è¯»äº† (RAG åŸºç¡€)
# ä»»åŠ¡: æ‰“é€ â€œChatPDFâ€åŸå‹ã€‚
# æŠ€æœ¯: PyPDFLoader (è¯»æ–‡ä»¶) + RecursiveCharacterTextSplitter (åˆ‡ç‰‡) + VectorStore (å‘é‡åŒ–å­˜å‚¨)ã€‚
# æˆæœ: ä¸Šä¼ ä¸€ä»½æ–‡æ¡£ï¼ŒAI èƒ½åŸºäºæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚

# // --- ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•°æ®å‡†å¤‡ ---
# å®šä¹‰ PDFè·¯å¾„ = "python_tutorial.pdf"

# æ–‡æ¡£ = PyPDFLoader(PDFè·¯å¾„).load()

# // åˆ‡åˆ†å™¨é…ç½®ï¼šæ¯å—1000å­—ï¼Œé‡å 200å­—
# åˆ‡åˆ†å™¨ = RecursiveCharacterTextSplitter(size=1000, overlap=200)
# æ–‡æœ¬å—åˆ—è¡¨ = åˆ‡åˆ†å™¨.split(æ–‡æ¡£)

# // å»ºåº“ï¼šæŠŠæ–‡æœ¬å—å˜æˆå‘é‡å­˜èµ·æ¥
# å‘é‡åº“ = Chroma.from_documents(æ–‡æœ¬å—åˆ—è¡¨, Embeddingæ¨¡å‹)


# // --- ç¬¬äºŒéƒ¨åˆ†ï¼šé—®ç­”å¾ªç¯ ---
# å½“ ç”¨æˆ·è¾“å…¥é—®é¢˜ æ—¶:
#     // 1. å»åº“é‡Œæ‰¾ç­”æ¡ˆç´ æ
#     å‚è€ƒç´ æ = å‘é‡åº“.search(ç”¨æˆ·é—®é¢˜, top_k=3)
    
#     // 2. å¡«ç©ºé¢˜æ¨¡å¼
#     æç¤ºè¯ = "è¯·æ ¹æ®ä»¥ä¸‹ç´ æï¼š{å‚è€ƒç´ æ}ï¼Œå›ç­”é—®é¢˜ï¼š{ç”¨æˆ·é—®é¢˜}"
    
#     // 3. è®© AI ä½œç­”
#     æœ€ç»ˆç­”æ¡ˆ = ChatOpenAI.predict(æç¤ºè¯)DASHSCOPE_API_KEY
    
#     æ‰“å°(æœ€ç»ˆç­”æ¡ˆ)




import os
from dotenv import load_dotenv
# å¯¼å…¥æˆ‘ä»¬çš„â€œè§£é¢˜å·¥å…·â€
from langchain_text_splitters import RecursiveCharacterTextSplitter

# åŠ è½½å™¨å’Œå‘é‡åº“ä»åœ¨ community ä¸­
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.chat_models import ChatTongyi

from langchain_classic.chains import create_retrieval_chain
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
# ã€é‡ç‚¹ 3ã€‘æç¤ºè¯æ¨¡æ¿åœ¨è¿™é‡Œ
from langchain_core.prompts import ChatPromptTemplate

# --- ä¿®æ”¹ A éƒ¨åˆ†ï¼šåŠ è½½æ–‡ä»¶ ---
# æŠŠåŸæ¥çš„ python_tutorial.pdf æ¢æˆä½ çš„è´¢æŠ¥æ–‡ä»¶å
# 1. åŠ è½½ç¯å¢ƒ
load_dotenv()

# --- ã€ä¿®æ”¹ç‚¹ã€‘è‡ªåŠ¨è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„ ---
current_dir = os.path.dirname(os.path.abspath(__file__))
# æ‹¼æ¥æˆå®Œæ•´çš„ç»å¯¹è·¯å¾„
pdf_path = os.path.join(current_dir, "TSLA-Q3-2025-Update.pdf")

print(f"ğŸ“‚ æ­£åœ¨å°è¯•åŠ è½½æ–‡ä»¶: {pdf_path}")

# æ£€æŸ¥ä¸€ä¸‹æ–‡ä»¶åˆ°åº•åœ¨ä¸åœ¨
if not os.path.exists(pdf_path):
    print("âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ï¼è¯·æ£€æŸ¥æ–‡ä»¶åæˆ–è·¯å¾„ã€‚")
else:
    loader = PyPDFLoader(pdf_path) # è¿™é‡Œä¼ å…¥ç»å¯¹è·¯å¾„
    docs = loader.load()
    print("âœ… åŠ è½½æˆåŠŸï¼")



print(f"1. æ­£åœ¨åŠ è½½ç‰¹æ–¯æ‹‰è´¢æŠ¥: {pdf_path} ...")
loader = PyPDFLoader(pdf_path)
documents = loader.load()
print(f"   -> åŠ è½½æˆåŠŸï¼å…± {len(documents)} é¡µã€‚")

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 1000,# æ¯ä¸ªç¢ç‰‡çº¦ 1000 å­—ç¬¦ï¼Œä¿è¯èƒ½è£…ä¸‹ä¸€ä¸ªå‡½æ•°
    chunk_overlap = 250,# é‡å  200 å­—ç¬¦ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡æ–­è£‚
)
texts = text_splitter.split_documents(documents)
print(f"   -> åˆ‡åˆ†æˆåŠŸï¼å…±åˆ‡æˆäº† {len(texts)} ä¸ªç¢ç‰‡ã€‚")

# --- C. å»ºåº“ (Store) ---
print("æ­£åœ¨å»ºç«‹å‘é‡æ•°æ®åº“ (è°ƒç”¨é˜¿é‡Œäº‘ text-embedding-v1)...")
# ã€ä¿®æ”¹ç‚¹ 2ã€‘ä½¿ç”¨é˜¿é‡Œäº‘çš„åµŒå…¥æ¨¡å‹
# model="text-embedding-v1" æ˜¯æ€§ä»·æ¯”å¾ˆé«˜çš„é€‰æ‹©

embeddings = DashScopeEmbeddings(model="text-embedding-v1",dashscope_api_key=os.getenv('ALIYUN_API_KEY'))
# å°†å‘é‡å­˜å…¥ Chroma æœ¬åœ°æ•°æ®åº“
db = Chroma.from_documents(documents = texts,embedding = embeddings)

retriever = db.as_retriever(search_kwargs={"k": 6})



system_template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç‰¹æ–¯æ‹‰è´¢æŠ¥åˆ†æå¸ˆã€‚
è¯·åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœä½ åœ¨æ–‡ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œå°±è¯´ä¸çŸ¥é“ã€‚

<context>
{context}
</context>
"""

# 2. æ„å»º ChatPromptTemplate
# system éƒ¨åˆ†åªåŒ…å« {context}
# human éƒ¨åˆ†åŒ…å« {input} (ä½ çš„é—®é¢˜)
prompt = ChatPromptTemplate.from_messages([
    ("system", system_template),
    ("human", "{input}"),
])

llm = ChatTongyi(model="qwen-turbo",dashscope_api_key=os.getenv('ALIYUN_API_KEY'))

# æ„å»ºæ–‡æ¡£é“¾ + æ£€ç´¢é“¾
question_answer_chain = create_stuff_documents_chain(llm, prompt)
rag_chain = create_retrieval_chain(retriever, question_answer_chain)

# 5. æé—®
# åŠ ä¸Šè‹±æ–‡å…³é”®è¯ "Gross Margin"
question = "ç‰¹æ–¯æ‹‰æœ¬å­£åº¦çš„ Gross Margin (æ¯›åˆ©ç‡) æ˜¯å¤šå°‘ï¼Ÿè¯·æ‰¾ä¸€ä¸‹ GAAP Gross Margin çš„æ•°æ®ã€‚"
print(f"ğŸš€ æé—®: {question}")
response = rag_chain.invoke({"input": question})

print("-" * 30)
print(f"å›ç­”: {response['answer']}")
print("-" * 30)

# --- æ‰“å° AI å‚è€ƒçš„åŸæ–‡ ---
print("\nğŸ” AI å‚è€ƒäº†ä»¥ä¸‹å†…å®¹ (Context):")
print("-" * 30)
# ä» response ä¸­æå– source_documents (æ–°ç‰ˆé“¾å¼å†™æ³•ä¼šè‡ªåŠ¨åŒ…å«åœ¨ context ä¸­)
for i, doc in enumerate(response["context"]):
    # åªæ‰“å°å‰ 100 ä¸ªå­—ï¼Œé˜²æ­¢åˆ·å±
    print(f"[ç‰‡æ®µ {i+1}] å†…å®¹æ‘˜è¦: {doc.page_content[:100]}...") 
    print(f"       (æ¥è‡ªç¬¬ {doc.metadata.get('page', '?')} é¡µ)")
    print("-" * 20)


